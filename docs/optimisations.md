# Optimisations

This document details the optimisation strategies used in the number combination solver, including implemented techniques, considered alternatives, and future opportunities.

## Implemented Optimisations

### 1. Meet-in-the-Middle Algorithm

**What:** Split large expressions (k>4) into two halves, generate subexpressions independently, then combine.

**Why:** Reduces time complexity from O(n^k) to O(n^(k/2))

**Impact:**
- Time: 100-10,000x faster for k>4
- Space: Similar to brute force (O(n^(k/2)))

**Implementation:**
```python
if num_count <= 4:
    return direct_search(...)
else:
    return meet_in_middle_search(...)
```

**See:** [Meet-in-the-Middle Algorithm](meet-in-middle.md)

---

### 2. Canonical Key Deduplication

**What:** Convert expressions to a canonical form to detect duplicates.

**Why:** Avoid showing mathematically equivalent expressions like `2 + 3` and `3 + 2`.

**Impact:**
- Time: Minimal overhead (~5%)
- Space: 50-80% reduction in stored solutions
- Quality: Much better user experience

**Implementation:**
```python
def canonical_key(expression: str) -> str:
    # 1. Split into addition/subtraction terms
    # 2. Normalise multiplication terms (sort factors)
    # 3. Sort positive terms, then negative terms
    # 4. Remove redundant parentheses
    return normalised_expression
```

**Example:**
```python
canonical_key("3 + 2")           # ‚Üí "+2+3"
canonical_key("2 + 3")           # ‚Üí "+2+3"  (duplicate detected!)
canonical_key("(3 * 2) + 1")     # ‚Üí "+1+2*3"
canonical_key("1 + (2 * 3)")     # ‚Üí "+1+2*3"  (duplicate detected!)
```

**Limitations:**
- Doesn't catch all mathematical equivalences (e.g., `2 * 3` vs `6`)
- Doesn't handle division/subtraction commutativity perfectly
- Trade-off: Simple and fast vs perfect deduplication

---

### 3. Limited Results Per Value

**What:** Store only the first `m` ways to create each intermediate value (default: m=3).

**Why:** Reduces memory and combination time without significantly affecting solution quality.

**Impact:**
- Time: 2-4x faster
- Space: 50-70% reduction
- Quality: Minimal impact (still find good solutions)

**Implementation:**
```python
if unlimited or len(results[value]) < max_results_per_value:
    results[value].append(PartialResult(...))
```

**Example:**
```python
# Without limit:
results[25] = [
    "5 * 5",
    "1 + 24",
    "2 + 23",
    "3 + 22",
    ... (100+ ways)
]

# With limit (m=3):
results[25] = [
    "5 * 5",      # First found
    "1 + 24",     # Second found
    "2 + 23",     # Third found
    # Stop here
]
```

**Rationale:** The first few ways to create a value are usually the simplest and most useful.

---

### 4. Early Termination

**What:** Stop searching when we have enough good solutions.

**Why:** No need to search k=6 if we already found excellent solutions at k=3.

**Impact:**
- Time: 30-50% faster on average
- Space: Minimal
- Quality: No impact (we keep the best solutions)

**Implementation:**
```python
for num_count in range(1, max_numbers + 1):
    solutions = search(num_count)
    all_solutions.update(solutions)
    
    # Early termination check
    if all_solutions:
        best_op_count = min(s.op_count for s in all_solutions)
        if best_op_count <= num_count - 1:
            if len(all_solutions) >= top_n:
                break  # We have enough good solutions
```

**Example:**
```python
# Target: 100, max_numbers: 6

k=1: No solutions
k=2: No solutions
k=3: Found "(4 * 5 * 5)" with 2 operations ‚úì
k=4: Found more solutions with 3 operations
# Stop here! We have 5 solutions, best has 2 ops, no need to try k=5,6
```

---

### 5. Integer Division Validation

**What:** Only allow division when the result is an exact integer.

**Why:** Beltmatic uses integer arithmetic; fractional results are invalid.

**Impact:**
- Time: 10-20% faster (skips invalid divisions)
- Space: Minimal
- Quality: Ensures correctness

**Implementation:**
```python
if ops[i] == '/':
    if nums[i + 1] == 0 or nums[i] % nums[i + 1] != 0:
        return None  # Invalid expression
    nums[i] = nums[i] // nums[i + 1]
```

**Example:**
```python
evaluate_expression([7, 2], ['/'])  # 7/2 = 3.5 ‚Üí None (invalid)
evaluate_expression([8, 2], ['/'])  # 8/2 = 4 ‚Üí 4 (valid)
```

---

### 6. Operator Precedence Handling

**What:** Evaluate expressions respecting standard operator precedence.

**Why:** Ensures mathematical correctness and minimal parentheses.

**Impact:**
- Time: Minimal overhead
- Space: Minimal
- Quality: Correct and readable expressions

**Implementation:**
```python
def evaluate_expression(numbers, operators):
    # Pass 1: Exponentiation (**)
    # Pass 2: Multiplication (*) and Division (/)
    # Pass 3: Addition (+) and Subtraction (-)
```

**Example:**
```python
evaluate_expression([2, 3, 4], ['+', '*'])
# Evaluates as: 2 + (3 * 4) = 2 + 12 = 14
# NOT: (2 + 3) * 4 = 5 * 4 = 20
```

---

### 7. Minimal Parenthesisation

**What:** Add parentheses only when necessary for correct precedence.

**Why:** Produces cleaner, more readable expressions.

**Impact:**
- Time: Minimal overhead
- Space: Slightly smaller expressions
- Quality: Much better readability

**Implementation:**
```python
def wrap_if_needed(expr, for_mult_div=False):
    if for_mult_div and ('+' in expr or '-' in expr):
        return f"({expr})"
    return expr
```

**Example:**
```python
# Without optimisation:
"((2) + (3)) * ((4) + (5))"

# With optimisation:
"(2 + 3) * (4 + 5)"
```

---

### 8. Recursive Meet-in-Middle

**What:** Apply meet-in-middle recursively for very large k.

**Why:** Maintains efficiency even for k>6.

**Impact:**
- Time: Enables k=10+ with reasonable performance
- Space: Controlled growth
- Quality: No impact

**Implementation:**
```python
def generate_all_subexpressions(num_count):
    if num_count <= 3:
        # Direct enumeration
    else:
        # Recursive split
        left = generate_all_subexpressions(num_count // 2)
        right = generate_all_subexpressions(num_count - num_count // 2)
        # Combine
```

---

## Considered but Not Implemented

### 1. Value Range Pruning

**What:** Skip intermediate values that are too large or too small to reach the target.

**Why not implemented:**
- Complex to determine "too large" dynamically
- Could miss valid solutions (e.g., large value divided down)
- Benefit unclear for typical inputs

**Potential impact:**
- Time: 20-40% faster
- Space: 30-50% reduction
- Risk: Could miss some solutions

**Future consideration:** Could implement with conservative bounds.

---

### 2. Symmetry Breaking

**What:** Avoid generating symmetric expressions like `a + b` and `b + a` during generation.

**Why not implemented:**
- Already handled by canonical key deduplication
- Would complicate generation logic
- Minimal additional benefit

**Potential impact:**
- Time: 10-20% faster
- Space: Minimal
- Complexity: Significantly higher

---

### 3. Memoisation Across Targets

**What:** Cache subexpression results for reuse across multiple target searches.

**Why not implemented:**
- Targets are typically searched independently
- Memory overhead for cache
- Limited reuse in practice

**Potential impact:**
- Time: 2-5x faster for multiple targets
- Space: 10-100x increase
- Use case: Batch processing many targets

**Future consideration:** Could implement for batch mode.

---

### 4. Bloom Filters for Existence Checks

**What:** Use Bloom filters for quick "does this value exist?" checks before hash table lookups.

**Why not implemented:**
- Hash table lookups are already O(1)
- Bloom filter overhead might exceed benefit
- Added complexity

**Potential impact:**
- Time: 5-15% faster (maybe)
- Space: 10-20% increase
- Complexity: Moderate

---

### 5. Expression Caching

**What:** Cache evaluated expressions to avoid re-evaluation.

**Why not implemented:**
- Expressions are typically evaluated once
- Memory overhead for cache
- Hash computation cost

**Potential impact:**
- Time: Minimal (expressions rarely re-evaluated)
- Space: Significant increase
- Benefit: Very low

---

## Future Optimisation Opportunities

### 1. Parallel Processing ‚≠ê‚≠ê‚≠ê

**What:** Generate left and right subexpressions in parallel threads.

**Potential impact:**
- Time: 1.5-2x faster on multi-core systems
- Space: No change
- Complexity: Moderate

**Implementation approach:**
```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=2) as executor:
    left_future = executor.submit(generate_all_subexpressions, left_count)
    right_future = executor.submit(generate_all_subexpressions, right_count)
    
    left_values = left_future.result()
    right_values = right_future.result()
```

**Priority:** High - Good benefit/complexity ratio

---

### 2. Adaptive max_results_per_value ‚≠ê‚≠ê

**What:** Start with m=1, increase to m=3 if insufficient solutions found.

**Potential impact:**
- Time: 2-3x faster for easy targets
- Space: 50% reduction for easy targets
- Complexity: Low

**Implementation approach:**
```python
for m in [1, 2, 3]:
    solutions = search(max_results_per_value=m)
    if len(solutions) >= top_n:
        break  # Found enough
```

**Priority:** Medium - Good for easy targets

---

### 3. GPU Acceleration ‚≠ê

**What:** Use GPU for massive parallel expression evaluation.

**Potential impact:**
- Time: 10-100x faster (for very large searches)
- Space: GPU memory required
- Complexity: Very high

**Challenges:**
- GPU programming complexity
- Data transfer overhead
- Limited benefit for typical inputs (already fast enough)

**Priority:** Low - Overkill for current use case

---

### 4. Incremental Search ‚≠ê‚≠ê

**What:** Search k=1, then k=2, etc., but reuse subexpressions from previous k.

**Potential impact:**
- Time: 20-30% faster
- Space: Moderate increase (caching)
- Complexity: Moderate

**Implementation approach:**
```python
cache = {}
for k in range(1, max_numbers + 1):
    # Reuse cache[k-1] when generating cache[k]
    cache[k] = generate_with_cache(k, cache)
```

**Priority:** Medium - Good for exhaustive searches

---

### 5. Machine Learning Pruning ‚≠ê

**What:** Train ML model to predict which subexpressions are likely to lead to solutions.

**Potential impact:**
- Time: 2-10x faster (maybe)
- Space: Model storage
- Complexity: Very high

**Challenges:**
- Training data collection
- Model accuracy
- Inference overhead
- Probably overkill

**Priority:** Very low - Academic interest only

---

## Optimisation Trade-offs

| Optimisation | Time | Space | Complexity | Quality | Implemented |
|--------------|------|-------|------------|---------|-------------|
| Meet-in-middle | +++++ | = | +++ | = | ‚úÖ |
| Canonical keys | - | +++++ | ++ | +++++ | ‚úÖ |
| Limited results | ++++ | ++++ | + | - | ‚úÖ |
| Early termination | +++ | = | + | = | ‚úÖ |
| Integer division | + | = | + | = | ‚úÖ |
| Precedence | = | = | ++ | +++++ | ‚úÖ |
| Min parentheses | = | + | ++ | ++++ | ‚úÖ |
| Recursive M-i-M | +++++ | = | +++ | = | ‚úÖ |
| Value pruning | ++ | ++ | +++ | -- | ‚ùå |
| Symmetry breaking | + | = | ++++ | = | ‚ùå |
| Memoisation | +++ | ----- | ++ | = | ‚ùå |
| Bloom filters | + | - | +++ | = | ‚ùå |
| Parallel | +++ | = | ++ | = | üîÆ Future |
| Adaptive m | ++ | ++ | + | = | üîÆ Future |

**Legend:**
- `+++++` = Huge improvement
- `+` = Small improvement
- `=` = No change
- `-` = Small degradation
- `-----` = Huge degradation

---

## Benchmarking Results

Performance comparison with and without key optimisations:

### Baseline (No Optimisations)

```
Target: 2285, max_int: 25, k: 6
Time: ~60 seconds
Memory: ~500 MB
Solutions: 50+ (many duplicates)
```

### With Meet-in-Middle Only

```
Time: ~5 seconds (12x faster)
Memory: ~100 MB (5x better)
Solutions: 50+ (many duplicates)
```

### With Meet-in-Middle + Limited Results (m=3)

```
Time: ~1.5 seconds (40x faster)
Memory: ~30 MB (16x better)
Solutions: 20+ (many duplicates)
```

### With All Optimisations (Current)

```
Time: ~0.23 seconds (260x faster)
Memory: ~5 MB (100x better)
Solutions: 5 (no duplicates, best quality)
```

---

## Optimisation Guidelines

### When to Use Exhaustive Mode

**Use `exhaustive=True` when:**
- You want ALL possible solutions
- Input is small (max_int ‚â§ 8, k ‚â§ 5)
- Time is not critical

**Avoid when:**
- Input is large (max_int > 10 or k > 6)
- You only need a few good solutions
- Performance matters

### When to Increase max_results_per_value

**Increase to 5-10 when:**
- Exhaustive mode is too slow
- You want more solution diversity
- Target is hard to reach

**Keep at 3 (default) when:**
- Performance matters
- You only need a few solutions
- Memory is limited

### When to Reduce max_numbers

**Reduce when:**
- Searches are too slow
- Target is small (likely reachable with fewer numbers)
- Memory is very limited

**Example:**
```python
# Target: 100, max_int: 8
# Try max_numbers: 4 first
# If no solutions, increase to 5, then 6
```

---

## Profiling Data

Breakdown of time spent in different parts of the algorithm (k=6, n=8, o=4):

| Component | Time % | Optimisation Opportunity |
|-----------|--------|--------------------------|
| Subexpression generation | 60% | ‚úÖ Already optimised (meet-in-middle) |
| Expression evaluation | 15% | ‚úÖ Already optimised (precedence) |
| Canonical key computation | 10% | ‚ö†Ô∏è Could optimise further |
| Hash table operations | 8% | ‚úÖ Already O(1) |
| Solution formatting | 5% | ‚úÖ Already optimised |
| Other | 2% | - |

**Conclusion:** Most time is spent in subexpression generation, which is already well-optimised with meet-in-middle.

---

## See Also

- [Algorithm Overview](algorithm-overview.md) - High-level explanation
- [Complexity Analysis](complexity-analysis.md) - Detailed complexity
- [Meet-in-the-Middle Algorithm](meet-in-middle.md) - Core algorithm
- [Design Decisions](design-decisions.md) - Why these optimisations were chosen
